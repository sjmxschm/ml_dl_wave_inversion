{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validate Networks with passing in entire test set or individual selected images\n",
    "\n",
    "The performance of the network might look better than it really is when evaluated on batches of the entire dataset. To solve this, an harder validation set is used which mainly contains samples from the harder to classify data set (simulations with thicknesses close to the threshold)\n",
    "\n",
    "--> Make sure to simulate an test data set which has not been used before for andy kind of training. The test set I used in my folder structure is more a validation set because I used it to tune the hyper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import necessary modules first"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "use cell below for import of matplotlib only if you want to plot for latex with .pgf later"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# comment this in if you want to export to latex\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_path = Path.cwd() / 'data'\n",
    "checkpoint_path = Path.cwd() / 'model_checkpoints'\n",
    "trained_path = Path.cwd() / 'trained_models'\n",
    "# sims_path = Path.cwd().parent.resolve() / 'analysis_2dfft'\n",
    "sims_path = Path('C:\\\\Users\\\\Max\\\\Documents') / 'analysis_2dfft'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from dl_code.testing import Tester\n",
    "from dl_code.my_resnet import MyResNet18, MyResNet34\n",
    "from dl_code.simple_net_big import SimpleNetBig\n",
    "\n",
    "from dl_code.data_transforms import get_all_transforms\n",
    "from dl_code.confusion_matrix import generate_and_plot_confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load network and testing class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# inp_size = (512, 512)\n",
    "inp_size = (1024, 1024)\n",
    "dataset_mean, dataset_std = 0.3150067262879628, 0.1554323642999201\n",
    "\n",
    "is_simple_net = True\n",
    "\n",
    "if is_simple_net:\n",
    "    simple_net_big = SimpleNetBig() # comment in leaky layer is runtime error\n",
    "    tester = Tester(\n",
    "        data_dir = data_path,\n",
    "        data_set = 'test',  #'train',  # \"test\",\n",
    "        model = simple_net_big,  #my_resnet, #simple_net_big,\n",
    "        is_checkpoint = False,\n",
    "        load_trained_model = True,\n",
    "        save_dir = trained_path,  # checkpoint_path / 'resnet18_cluster',\n",
    "        model_name = '02-04_01-13-40_trained_SimpleNetBig_final.pt', #'01-15_01-13-45_trained_SimpleNetBig_final.pt', # '01-13_16-43-56_trained_SimpleNetBig_final.pt', ##'01-11_10-16-03_trained_SimpleNetBig_final.pt',  # '01-10_20-47-01_trained_SimpleNetBig_final.pt',  #'12-07_15-47-20_trained_SimpleNetBig_final.pt',  #'01-07_19-13-04_trained_MyResNet18_final.pt',#'12-07_15-47-20_trained_SimpleNetBig_final.pt', #'01-07_19-13-04_trained_MyResNet18_final.pt', #'12-06_00-46-09_trained_SimpleNetBig_final.pt',  # \"11-18_13-57-46_trained_MyResNet34_final.pt\",  #'trained_MyResNet18_final.pt',  #,'trained_SimpleNetBig_final_v1.pt',  #'checkpoint.pt',\n",
    "        data_transforms = get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "        sims_path = sims_path,\n",
    "        batch_size = 1, #32,\n",
    "        cuda = True,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "if not is_simple_net:\n",
    "    my_resnet = MyResNet18()\n",
    "    # my_resnet = MyResNet34()\n",
    "    tester = Tester(\n",
    "        data_dir = data_path,\n",
    "        data_set = 'train',  # \"test\",\n",
    "        model = my_resnet,  #my_resnet, #simple_net_big,\n",
    "        is_checkpoint = True,\n",
    "        load_trained_model = True,\n",
    "        save_dir = checkpoint_path / 'resnet18_cluster',  # trained_path,  # checkpoint_path / 'resnet18_cluster',\n",
    "        model_name = 'checkpoint.pt',  # '01-10_20-47-01_trained_SimpleNetBig_final.pt',  #'12-07_15-47-20_trained_SimpleNetBig_final.pt',  #'01-07_19-13-04_trained_MyResNet18_final.pt',#'12-07_15-47-20_trained_SimpleNetBig_final.pt', #'01-07_19-13-04_trained_MyResNet18_final.pt', #'12-06_00-46-09_trained_SimpleNetBig_final.pt',  # \"11-18_13-57-46_trained_MyResNet34_final.pt\",  #'trained_MyResNet18_final.pt',  #,'trained_SimpleNetBig_final_v1.pt',  #'checkpoint.pt',\n",
    "        data_transforms = get_all_transforms(inp_size, [dataset_mean], [dataset_std]),\n",
    "        sims_path = sims_path,\n",
    "        batch_size = 1, #32,\n",
    "        cuda = True,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run a batch of images trough the Network\n",
    "\n",
    "Function only makes sense when batch size is 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of batch --> = 0.0\n",
      "loss of batch ------> = 0.7550636529922485\n",
      "true labels --------> = [1]\n",
      "probabilities ------> = \n",
      "[[0.53001934 0.46998066]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc, loss, probs, y = tester.push_batch()\n",
    "\n",
    "print(f'accuracy of batch --> = {acc}\\n'\n",
    "      f'loss of batch ------> = {loss}\\n'\n",
    "      f'true labels --------> = {y}\\n'\n",
    "      f'probabilities ------> = \\n{probs}\\n'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run just a single example through the Network\n",
    "\n",
    "Select an index smaller or equal the length of the dataset as below:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length = 122\n"
     ]
    }
   ],
   "source": [
    "dataset_length = tester.dataset_length\n",
    "print(f'dataset length = {dataset_length}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thickness ----------------->: 290.0 microns\n",
      "Gap_depth ----------------->: 75.0 microns\n",
      "Predicted class of sample ->: 0\n",
      "True class of sample ------>: 0\n",
      "probability of prediction ->: 0.555\n",
      "\n",
      "<class 'int'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'float'> <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "idx = 90\n",
    "\n",
    "gt_c, p_c, prob, thick, gd = tester.push_single(idx)\n",
    "\n",
    "print(\n",
    "    f'Thickness ----------------->: {thick} microns\\n'\n",
    "    f'Gap_depth ----------------->: {gd} microns\\n'\n",
    "    f'Predicted class of sample ->: {int(p_c)}\\n'\n",
    "    f'True class of sample ------>: {gt_c}\\n'\n",
    "    f'probability of prediction ->: {\"{:.3f}\".format(float(prob.ravel()))}\\n'\n",
    ")\n",
    "\n",
    "print(type(gt_c), type(p_c), type(prob), type(thick), type(gd))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Push whole test set though network and get labels for plotting later:\n",
    "This is a necessary step for plotting later"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\OneDrive - Georgia Institute of Technology\\Documents\\Uni Gatech MSC\\A Lab Research Wave CEE\\python_scripts\\dl_code\\testing.py:128: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  f[idx, :] = np.array(self.push_single(idx))\n"
     ]
    }
   ],
   "source": [
    "f_all = tester.push_all()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract ground truth Thickness\n",
    "\n",
    "Extract the real thickness for all elements in\n",
    "__test set__!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# from create_model.visualize_dataset import get_thickness_info\n",
    "\n",
    "thick_threshold = 204\n",
    "\n",
    "features = np.zeros((tester.dataset_length, 2))\n",
    "real_thicks = []\n",
    "for idx in range(tester.dataset_length):\n",
    "    thick, gd = tester.get_simulation_information(idx, sims_path)\n",
    "    features[idx, 0] = thick * 1E-6\n",
    "    features[idx, 1] = gd * 1E-6\n",
    "    real_thicks.append(thick - gd)\n",
    "\n",
    "# get_thickness_info(features, thick_threshold, save=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot the prediction data\n",
    "\n",
    "Create a scatter plot with gap depth over thickness, color the data points according to their prediction and adjust the size of the dots according to the accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-859a8a178c48>:39: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "thick_threshold = 200\n",
    "\n",
    "f = f_all[:-1,:]\n",
    "# print(f)\n",
    "\n",
    "fig = plt.figure(1, dpi=200)\n",
    "fig.set_size_inches(w=6, h=4)\n",
    "ax = plt.gca()\n",
    "\n",
    "# print(f)\n",
    "\n",
    "f_color = ['g' if elem[1] == 1 else 'r' for elem in f]\n",
    "f_markers = [\"D\" if elem[1] == 1 else \"o\" for elem in f]\n",
    "f_size = [50 if elem[1] == 1 else 50 for elem in f]\n",
    "# ax.scatter(f[:, 3], f[:, 4], s=40, c=f_color, alpha=0.8) # s=f[:, 2]*100\n",
    "for idx in range(len(f_markers)):\n",
    "    ax.scatter(f[idx, 3], f[idx, 4], s=f_size[idx],\n",
    "               marker=f_markers[idx], c=f_color[idx], alpha=0.8) # s=f[:, 2]*100\n",
    "\n",
    "x = np.linspace(0, 600, 100)\n",
    "# y = x - thick_threshold\n",
    "y = 2*np.ones((len(x),1))\n",
    "ax.plot(x, y, c='k')\n",
    "\n",
    "# import pdb; pdb.set_trace()\n",
    "\n",
    "plt.axis([-10, 610, -10, 210])\n",
    "# plt.title(f'CNN classification for test set\\n'\n",
    "#           f'12/06/2021 v2')\n",
    "plt.xlabel(r'Coating thickness in $\\mu$m (1E-6m)')\n",
    "plt.ylabel(r'Gap depth in $\\mu$m (1E-6m)')\n",
    "\n",
    "date = '02042022_' # '12062021'\n",
    "net = 'SimpleNetBig' #'ResNet18' # 'SimpleNetBig'\n",
    "if True:\n",
    "    plt.savefig(f'./figures/{date}_test_set_classification_{net}_v4.png', dpi=200)\n",
    "    plt.savefig(f'./figures/{date}_test_set_classification_{net}_v4.pgf',\n",
    "                 bbox_inches='tight', backend='pgf', format='pgf', dpi=100)\n",
    "plt.show()\n",
    "plt.close(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.96 GiB (GPU 0; 4.00 GiB total capacity; 2.23 GiB already allocated; 69.90 MiB free; 2.34 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-d00762f15708>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m generate_and_plot_confusion_matrix(simple_net_big, tester.dataset,\n\u001B[0m\u001B[0;32m      2\u001B[0m                                    save_matrix=True, use_cuda=True)\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Georgia Institute of Technology\\Documents\\Uni Gatech MSC\\A Lab Research Wave CEE\\python_scripts\\dl_code\\confusion_matrix.py\u001B[0m in \u001B[0;36mgenerate_and_plot_confusion_matrix\u001B[1;34m(model, dataset, network_name, use_cuda, save_matrix)\u001B[0m\n\u001B[0;32m    200\u001B[0m     \"\"\"\n\u001B[0;32m    201\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 202\u001B[1;33m     targets, predictions, class_labels = generate_confusion_data(\n\u001B[0m\u001B[0;32m    203\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0muse_cuda\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_cuda\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m     )\n",
      "\u001B[1;32m~\\OneDrive - Georgia Institute of Technology\\Documents\\Uni Gatech MSC\\A Lab Research Wave CEE\\python_scripts\\dl_code\\confusion_matrix.py\u001B[0m in \u001B[0;36mgenerate_confusion_data\u001B[1;34m(model, dataset, use_cuda)\u001B[0m\n\u001B[0;32m     57\u001B[0m             \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# corresponding label\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m         \u001B[0mlogits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m         \u001B[0mmost_likely_label\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\cs6476_proj6\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Georgia Institute of Technology\\Documents\\Uni Gatech MSC\\A Lab Research Wave CEE\\python_scripts\\dl_code\\simple_net_big.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    105\u001B[0m         \u001B[1;31m# pdb.set_trace() # torch.Size([1, 1, 512, 512]) - torch.Size([1, 1, 1024, 1024]) -\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 107\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv_layers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    108\u001B[0m         \u001B[1;31m# pdb.set_trace()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m         \u001B[1;31m# x = self.conv_layers_leakyrelu(x)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\cs6476_proj6\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\cs6476_proj6\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    117\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 119\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    120\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\cs6476_proj6\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\cs6476_proj6\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 399\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    400\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\cs6476_proj6\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    393\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    394\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m--> 395\u001B[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[0;32m    396\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 1.96 GiB (GPU 0; 4.00 GiB total capacity; 2.23 GiB already allocated; 69.90 MiB free; 2.34 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "generate_and_plot_confusion_matrix(simple_net_big, tester.dataset,\n",
    "                                   save_matrix=True, use_cuda=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}